# CAP定理

分散システムにおいて、以下の3つのうち満たすことができるのは最大2つという定理。
Eric Brewer が[予想][1]し、Seth Gilbert, Nancy Lynch が[証明][2]した。  
Eric Brewer 自身が2012年に [The "2 of 3" formulation was always misleading ][6] と表明しており、「2つは満たせるが、残り 1つは全く満たすことができない」と解釈するのではなく、残り 1つは「常に満たすこと」は不可能だが「いづれ満たすこと」は可能である、と解釈することが必要だ。

### Consistency (一貫性)

全ノードで同時に同じデータが見えること。

### Availability (可用性)

死亡 (ダウン) していない生存中のノードが常に応答を反すこと。  
これを実現するには、**単一点障害** が無いことが必要。

Nancy Lynch による CAP定理の証明では、Availability を以下のように説明している。

> For a distributed system to be continuously available, every request received by a non-failing node in the system must result in a response.
> That is, any algorithm used by the service must eventually terminate. In some ways this is a weak definition of availability:
> it puts no bound on how long the algorithm may run before terminating, and therefore allows unbounded computation.
> On the other hand, when qualified by the need for partition tolerance, this can be seen as a strong definition of availability:
> even when severe network failures occur, every request must terminate.

[意訳]

分散システムが可用性を満たすとは、

可用性の弱い定義:  
**「システム内の非障害ノードが受け取った全てのリクエストに応答する。」**

これは、サービスによって使用される任意のアルゴリズムはいづれ停止しなければならないことを意味する。可用性の弱い定義とも言える。それは、アルゴリズムが停止するまでの時間に制限を設けておらず、したがって無制限の計算を許可する。
一方で、分断耐性は必要であるという制約を加えると、可用性の強い定義を得られる。

可用性の強い定義:  
**「ネットワーク障害が発生しても、全てのリクエストに応答する。」**

[私見]

強い定義は「分断耐性の制約」を加えたとて、アルゴリズムが停止するまでの時間に制限を設けている訳ではない。

A と独立して P の定義があることから、ここでいう「弱い定義」の方が無駄な制約を省き、より広範にカバーする強い定義と言える。

と、ここまで考えると、弱い定義も「非障害ノード」という C に関わる制約を含んでいることに気づく
(一般的 直感的に、障害ノードの発生は一貫性を喪失させる)。

この制約も外せば、可用性の定義は **「全てのリクエストに応答する」** だけで済む。
この定義は、システムが可用性を満たすために必要な条件を明確に示している。

### Partition tolerance (分断耐性)

システムが NP (Network Partition = ネットワーク分断) 状態でも継続して動作を行うこと。  
NP後、両方を生存させ、一貫性を失った動作が続くのは、APシステムであり、
NP後、一方を死亡させ、一貫性を保った動作が続くのは、CPシステムである。

## CAP定理から見た Database

DB の ACID性を支える仕組みに 2PC(2フェーズコミット)、 3PC(3フェーズコミット) があるが、
Henry Robinson による [Paxos (分散合意アルゴリズム) の説明][3] を借りると、

- 2PC は シングルノードの障害が処理をブロックするという単一点障害があり、可用性が犠牲になる。
- 3PC は 単一点障害を克服したが、「NP状態になり、双方で異なる更新が行われた後、NP状態が解消したとき」 に、一貫性が犠牲になる。

NoSQL系 DB は、可用性と分断耐性を保障して、一貫性を弱めるデザインになっている。
(結果一貫性 (Eventual Consistency) という弱い一貫性モデルを用いる)


## CAP定理から見た HAクラスタ

共有ディスク型クラスタとデータミラー型クラスタとが一貫性、可用性、分断耐性をいかに扱うかを見る。

以下 C = 一貫性、 A = 可用性、 P = 分断耐性 とする。

HAクラスタは APシステム である。

## 共有ディスク型クラスタ

NP後、多数派ノード群に現用系ノードを作り(フェイルオーバー) 共有ディスクをリザーブする。
少数派ノード群は共有ディスクへのアクセスを失い(C を失う)、全ノード稼働継続する(A を満たす)。

## データミラー型クラスタ

NP によって、複数のノードが異なる更新データを持つようになり、一貫性が回復不能となるのを防ぐために、STONITH や Quorum でデータ更新を行わないノードを停止することで A を満たす。

データミラー型クラスタは データの再同期処理を実装するが、NP発生から再同期完了までの間は C を失う (結果整合性: Eventual Consistency を得る)。

## データミラー型クラスタが結果一貫性を満たすケース

上で 「データの再同期処理を実装」するものの C を失う事を示したが、これは一時的に「ノードAで読んだデータとノードBで読んだデータが異なる状態」を許しており、**強い一貫性** を満たさないことを意味している。
しかし、何れかの時点で一貫性を回復することは可能で、この場合 **弱い一貫性** (結果一貫性) を満たす。
以下にデータミラー型クラスタが **結果一貫性** を満たす場合を示す。  
DBにおける 3PC同様、HAクラスタといえども NP によって一貫性を失いうることに注意。

1. 初期状態では node1 から node2 へレプリケーションを行っている。

2. node1 が遅延状態 若しくは NP状態へ突入し、NP対処処理が始まる。

3. node3 (例: Gateway server や Witness server) と通信不能なノードは自殺し、通信可能なノードが生き残る。自殺ノードが持つデータは更新されなくなり、生存ノードの持つデータは更新され、**一貫性を失う**。

4. NP状態の原因となった故障を修復したら、自殺ノードを起動する。

5. 生存ノードのデータで自殺ノードのデータを上書きすることで **一貫性を取り戻す**。


## 分散合意アルゴリズム イントロ

遅延による影響を克服可能なアルゴリズムとして登場したのが Paxos。 Paxosの課題は

- シンプルで数学的に検証されているが、実用には拡張が必要で、拡張実装の動作の正しさが不明。
- 理解しにくい。

であるとして、Paxosに代わるものとして提案されたのが [Raft][5]

伝統的なHAクラスタは 二層コミットによる分散ロックを使ってクラスタの状態とその遷移について一貫性を得た。
これの欠点は、
- 一貫性： 不作為障害を仮定しないため、遅延によって一貫性を失った後、それを取り戻すデザインが省略されるか、不完全なものになる。
- 可用性： SPoFを排除するために ありとあらゆる部分を二重化することを求めるが、業務継続を保証できるのは、「1カ所の故障」であって 2カ所以上の(同時)故障に対処できない。
- NP耐性： NPになった後、STONITHによる他殺を仮定するが、STONITHが可能であるなら その状態は NPではない、という矛盾

近い将来の HAクラスタは Raft を取り込んで以下を実現することが期待される。
- クラスタを３N+1ノード以上で構成し Nカ所の不作為障害に対処したうえで、結果一貫性 を実現する。
- 伝統的なHAクラスタがSPoFを排除するために ありとあらゆる部分を二重化することを求めることを 緩和する。
- NPになった後、リーダー完全性を基に STONITHに依存せずとも 一貫性を失わずに済むようにする。

伝統的なHAクラスタの工夫のしどころは、いかに APシステムを実現するかであった。
今日のHAクラスタは 如何に Cを弱める度合いを小さくするか、に腐心する (アルゴリズムの性能を向上させ、一貫性の回復に要する時間を短縮する工夫を競う)。

## 課題
- HAクラスタソフトが採用している[一環性モデル][4]を分類せよ。

- CAP定理に基づき HAクラスタソフトの強化を考察せよ。
	- 一貫性を弱める   : 一貫性を弱める方法に「結果一貫性」を用いる以外の方法は無いだろうか。
	- 可用性を弱める   : 可用性を弱めた HAクラスタを考察せよ。
		-  障害が発生してからフェイルオーバが完了するまでの間 サービスは止まる。したがって、ミクロに見れば、実はHAクラスタといえども A を満たしていない (弱めている)。
		- 「単一点障害の存在を許すHAクラスタ」とはどのようなものだろうか。
			- 単一点障害が発生するとシステムが止まるため A が失い、HAクラスタとして成立しない。
	- 分断耐性を弱める : 「強い一貫性と可用性を満たす HAクラスタ」に対して「分断耐性の弱め方」はありえるだろうか。

[1]: http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf
[2]: https://dl.acm.org/doi/epdf/10.1145/564585.564601
[3]: http://the-paper-trail.org/blog/consensus-protocols-paxos/
[4]: http://ossforum.jp/node/840
[5]: https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf
[6]: http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed
